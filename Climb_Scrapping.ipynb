{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nettoyage du DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open du fichier JSON\n",
    "with open('spots_grimpe.json', 'r') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON TO DF\n",
    "df = pd.DataFrame(data['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des colonnes\n",
    "df = df.drop(columns= [\"ref_topo\", \"equipement\", \"topo_num\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supression du tiret situé à la fin\n",
    "def sup_tiret(row):\n",
    "    return row.rstrip(\"-\")\n",
    "\n",
    "\n",
    "df[\"type_escalade\"] = df[\"type_escalade\"].apply(sup_tiret)\n",
    "df[\"exposition\"] = df[\"exposition\"].apply(sup_tiret)\n",
    "df[\"public\"] = df[\"public\"].apply(sup_tiret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création de liste à la place d'une chaîne de caractéres\n",
    "def split_list(row):\n",
    "    return row.split(\"-\")\n",
    "\n",
    "df[\"type_escalade\"] = df[\"type_escalade\"].apply(split_list)\n",
    "df[\"exposition\"] = df[\"exposition\"].apply(split_list)\n",
    "df[\"public\"] = df[\"public\"].apply(split_list)\n",
    "df[\"saison\"] = df[\"saison\"].apply(split_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remplacer \"hautniveau\" par \"haut niveau\" dans les listes\n",
    "df['public'] = df['public'].apply(lambda lst: ['haut niveau' if x == 'hautniveau' else x for x in lst])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionnaire de mappage\n",
    "mapping_orientation = {\n",
    "    \"S\": \"Sud\",\n",
    "    \"N\": \"Nord\",\n",
    "    \"W\": \"Ouest\",\n",
    "    \"E\": \"Est\",\n",
    "    \"SW\": \"Sud-Ouest\",\n",
    "    \"SE\": \"Sud-Est\",\n",
    "    \"NW\": \"Nord-Ouest\",\n",
    "    \"NE\": \"Nord-Est\"\n",
    "}\n",
    "\n",
    "# Appliquer le mappage aux listes dans la colonne \"exposition\"\n",
    "df[\"exposition\"] = df[\"exposition\"].apply(lambda lst: [mapping_orientation.get(el, el) for el in lst])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionnaire de mappage\n",
    "mapping_mois = {\n",
    "    \"1\": \"Janvier\",\n",
    "    \"2\": \"Février\",\n",
    "    \"3\": \"Mars\",\n",
    "    \"4\": \"Avril\",\n",
    "    \"5\": \"Mai\",\n",
    "    \"6\": \"Juin\",\n",
    "    \"7\": \"Juillet\",\n",
    "    \"8\": \"Août\",\n",
    "    \"9\": \"Septembre\",\n",
    "    \"10\": \"Octobre\",\n",
    "    \"11\": \"Novembre\",\n",
    "    \"12\": \"Decembre\"\n",
    "\n",
    "}\n",
    "\n",
    "# Appliquer le mappage aux listes dans la colonne \"saison\"\n",
    "df[\"saison\"] = df[\"saison\"].apply(lambda lst: [mapping_mois.get(el, el) for el in lst])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fk/s9b7316s21b6krxxntv4pzzm0000gn/T/ipykernel_6263/3093565319.py:2: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df['url'] = df['nom'].str.replace('(', '').str.replace(')', '').str.replace(' - ', '-').str.replace(' ', '-')\n"
     ]
    }
   ],
   "source": [
    "# Suppression des () et des - puis remplacer les espaces par des tirets pour l'url\n",
    "df['url'] = df['nom'].str.replace('(', '').str.replace(')', '').str.replace(' - ', '-').str.replace(' ', '-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrapping des urls des images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config BS4\n",
    "url = \"https://climbingaway.fr/fr/site-escalade/\"\n",
    "navigator = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrap de la class li de la page\n",
    "def scrap_url_img(row):\n",
    "    img_url = \"https://climbingaway.fr/\"\n",
    "    base_url = \"https://climbingaway.fr/fr/site-escalade/\"\n",
    "    page_url = row['url']  # Assurez-vous que cette colonne existe dans votre DataFrame\n",
    "    \n",
    "    # Envoie une requête pour récupérer la page HTML\n",
    "    response = requests.get(base_url + page_url, headers={'User-Agent': navigator})\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Trouve la première balise <li> avec la classe 'minie_galerie_li'\n",
    "    class_li = soup.find_all('li', {\"class\": \"minie_galerie_li\"})\n",
    "    \n",
    "    if class_li:\n",
    "        # Extraire l'URL de l'image\n",
    "        url_img = class_li[0].find('img').get('src')\n",
    "        \n",
    "        # Nettoyer l'URL en enlevant '/..' au début\n",
    "        cleaned_url = url_img.lstrip('/..')\n",
    "        \n",
    "        # Retourner l'URL complète\n",
    "        return img_url + cleaned_url\n",
    "    return None  # Si aucune image n'est trouvée\n",
    "\n",
    "df['img_url'] = df.progress_apply(scrap_url_img, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export CSV\n",
    "df.to_csv(\"spots_grimpe_folium.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CSV\n",
    "df = pd.read_csv(\"spots_grimpecsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
